{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\ANACONDA PYTHON\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.cm as cm\n",
    "from scipy import ndimage\n",
    "from skimage.measure import regionprops\n",
    "from skimage import io\n",
    "from skimage.filters import threshold_otsu\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.python.framework import ops\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Orginal_Signatures = \"F:\\\\Aac dataset\\\\Dataset\\\\real/\"\n",
    "Fake_Signatures = \"F:\\\\Aac dataset\\\\Dataset\\\\forged/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ColorToGray(img):\n",
    "    Grayimage = np.zeros((img.shape[0], img.shape[1]))\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[i])):\n",
    "            Grayimage[i][j] = np.average(img[i][j])\n",
    "    return Grayimage\n",
    "def GrayToBinary(img):\n",
    "    blur_radius = 0.8\n",
    "    img = ndimage.gaussian_filter(img, blur_radius)\n",
    "    ThresholdFreq = threshold_otsu(img)\n",
    "    BinaryImg = img > ThresholdFreq\n",
    "    BinaryImg = np.logical_not(BinaryImg)\n",
    "    return BinaryImg\n",
    "def PreProccesing(path, img=None, display=True):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    if display:\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "    Grey = ColorToGray(img)\n",
    "    if display:\n",
    "        plt.imshow(Grey, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    BinaryImg = GrayToBinary(Grey)\n",
    "    if display:\n",
    "        plt.imshow(BinaryImg, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    r, c = np.where(BinaryImg==1)\n",
    "    SignatureImage = BinaryImg[r.min(): r.max(), c.min(): c.max()]\n",
    "    if display:\n",
    "        plt.imshow(SignatureImage, cmap = matplotlib.cm.Greys_r)\n",
    "        plt.show()\n",
    "    return SignatureImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculating_Ratio(img):\n",
    "    pixels = 0\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[0])):\n",
    "            if img[i][j]==True:\n",
    "                pixels += 1\n",
    "    total_pixels = img.shape[0] * img.shape[1]\n",
    "    return pixels/total_pixels\n",
    "def Calculating_EccentricityAndSolidity(img):\n",
    "    region = regionprops(img.astype(\"int8\"))\n",
    "    return region[0].eccentricity, region[0].solidity\n",
    "def Calculating_SkewKurtosis(img):\n",
    "    h,w = img.shape\n",
    "    x = range(w)\n",
    "    y = range(h)\n",
    "    xp = np.sum(img,axis=0)\n",
    "    yp = np.sum(img,axis=1)\n",
    "    cx = np.sum(x*xp)/np.sum(xp)\n",
    "    cy = np.sum(y*yp)/np.sum(yp)\n",
    "    x2 = (x-cx)**2\n",
    "    y2 = (y-cy)**2\n",
    "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
    "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
    "    x3 = (x-cx)**3\n",
    "    y3 = (y-cy)**3\n",
    "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
    "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
    "    x4 = (x-cx)**4\n",
    "    y4 = (y-cy)**4\n",
    "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
    "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
    "\n",
    "    return (skewx , skewy), (kurtx, kurty)\n",
    "def Calculating_Centroid(img):\n",
    "    NumberOfWhites = 0\n",
    "    a = np.array([0,0])\n",
    "    for i in range(len(img)):\n",
    "        for j in range(len(img[0])):\n",
    "            if img[i][j]==True:\n",
    "                b = np.array([i,j])\n",
    "                a = np.add(a,b)\n",
    "                NumberOfWhites += 1\n",
    "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
    "    centroid = a/NumberOfWhites\n",
    "    centroid = centroid/rowcols\n",
    "    return centroid[0], centroid[1]\n",
    "def Feature_Extraction(path, img=None, display=False):\n",
    "    if img is None:\n",
    "        img = mpimg.imread(path)\n",
    "    img = PreProccesing(path, display=display)\n",
    "    ratio = Calculating_Ratio(img)\n",
    "    centroid = Calculating_Centroid(img)\n",
    "    eccentricity, solidity = Calculating_EccentricityAndSolidity(img)\n",
    "    skewness, kurtosis = Calculating_SkewKurtosis(img)\n",
    "    feature_tuple = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
    "    features = (feature_tuple[0], feature_tuple[1][0], feature_tuple[1][1], feature_tuple[2], feature_tuple[3], feature_tuple[4][0], feature_tuple[4][1], feature_tuple[5][0], feature_tuple[5][1])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Manipulation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeCSV():\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\Features')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\Features')\n",
    "        print('New folder \"Features\" created')\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\Features/Training')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\Features/Training')\n",
    "        print('New folder \"Features/Training\" created')\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\Features/Testing')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\Features/Testing')\n",
    "        print('New folder \"Features/Testing\" created')\n",
    "    for person in range(1,13):\n",
    "        per = ('00'+str(person))[-3:]\n",
    "        print('Saving features for person id-',per)\n",
    "        \n",
    "        with open('F:\\\\Aac dataset\\\\Dataset\\\\Features\\\\Training/training_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(Orginal_Signatures, per+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(0,3):\n",
    "                source = os.path.join(Fake_Signatures, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')\n",
    "        \n",
    "        with open('F:\\\\Aac dataset\\\\Dataset\\\\Features\\\\Testing/testing_'+per+'.csv', 'w') as handle:\n",
    "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
    "            for i in range(3, 5):\n",
    "                source = os.path.join(Orginal_Signatures, per+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',1\\n')\n",
    "            for i in range(3,5):\n",
    "                source = os.path.join(Fake_Signatures, '021'+per+'_00'+str(i)+'.png')\n",
    "                features = Feature_Extraction(path=source)\n",
    "                handle.write(','.join(map(str, features))+',0\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA PYTHON\\lib\\site-packages\\skimage\\measure\\_regionprops.py:250: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See https://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n",
      "D:\\ANACONDA PYTHON\\lib\\site-packages\\skimage\\measure\\_regionprops.py:260: UserWarning: regionprops and image moments (including moments, normalized moments, central moments, and inertia tensor) of 2D images will change from xy coordinates to rc coordinates in version 0.16.\n",
      "See https://scikit-image.org/docs/0.14.x/release_notes_and_installation.html#deprecations for details on how to avoid this message.\n",
      "  warn(XY_TO_RC_DEPRECATION_MESSAGE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving features for person id- 002\n",
      "Saving features for person id- 003\n",
      "Saving features for person id- 004\n",
      "Saving features for person id- 005\n",
      "Saving features for person id- 006\n",
      "Saving features for person id- 007\n",
      "Saving features for person id- 008\n",
      "Saving features for person id- 009\n",
      "Saving features for person id- 010\n",
      "Saving features for person id- 011\n",
      "Saving features for person id- 012\n"
     ]
    }
   ],
   "source": [
    "makeCSV()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Flow Model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter person's id : 012\n",
      "Enter path of signature image : F:\\\\Aac dataset\\\\Dataset\\\\forged\\\\021012_000.png\n",
      "Forged Image\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def WritingFeatures(path):\n",
    "    ExtractedFeatures = Feature_Extraction(path)\n",
    "    if not(os.path.exists('F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures')):\n",
    "        os.mkdir('F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures')\n",
    "    with open('F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures/testcsv.csv', 'w') as handle:\n",
    "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
    "        handle.write(','.join(map(str, ExtractedFeatures))+'\\n')\n",
    "        \n",
    "n_input = 9\n",
    "train_person_id = input(\"Enter person's id : \")\n",
    "test_image_path = input(\"Enter path of signature image : \")\n",
    "train_path = 'F:\\\\Aac dataset\\\\Dataset\\\\Features\\\\Training/training_'+train_person_id+'.csv'\n",
    "WritingFeatures(test_image_path)\n",
    "test_path = 'F:\\\\Aac dataset\\\\Dataset\\\\TestFeatures/testcsv.csv'\n",
    "\n",
    "def readCSV(train_path, test_path, type2=False):\n",
    "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
    "    train_input = np.array(df.values)\n",
    "    train_input = train_input.astype(np.float32, copy=False)\n",
    "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
    "    temp = [elem[0] for elem in df.values]\n",
    "    correct = np.array(temp)\n",
    "    corr_train = keras.utils.np_utils.to_categorical(correct,2) \n",
    "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
    "    test_input = np.array(df.values)\n",
    "    test_input = test_input.astype(np.float32, copy=False)\n",
    "    if not(type2):\n",
    "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
    "        temp = [elem[0] for elem in df.values]\n",
    "        correct = np.array(temp)\n",
    "        corr_test = keras.utils.np_utils.to_categorical(correct,2) \n",
    "    if not(type2):\n",
    "        return train_input, corr_train, test_input, corr_test\n",
    "    else:\n",
    "        return train_input, corr_train, test_input\n",
    "\n",
    "ops.reset_default_graph()\n",
    "\n",
    "learning_rate = 0.001\n",
    "training_epochs = 1000\n",
    "display_step = 1\n",
    "\n",
    "n_hidden_1 = 7 \n",
    "n_hidden_2 = 10\n",
    "n_hidden_3 = 30 \n",
    "n_classes = 2 \n",
    "\n",
    "\n",
    "X = tf.compat.v1.placeholder(dtype = tf.float32 ,shape= [None, n_input])\n",
    "Y = tf.compat.v1.placeholder(dtype = tf.float32 ,shape= [None, n_classes])\n",
    "\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], seed=2))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=3)),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes], seed=4))\n",
    "}\n",
    "\n",
    "\n",
    "def multilayer_perceptron(x):\n",
    "    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n",
    "    return out_layer\n",
    "\n",
    "logits = multilayer_perceptron(X)\n",
    "\n",
    "\n",
    "loss_op = tf.reduce_mean(tf.squared_difference(logits, Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "pred = tf.nn.softmax(logits) \n",
    "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "def evaluate(train_path, test_path, type2=False):   \n",
    "    if not(type2):\n",
    "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
    "    else:\n",
    "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
    "    ans = 'Random'\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(training_epochs):\n",
    "            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n",
    "            if cost<0.0001:\n",
    "                break\n",
    "        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n",
    "        if type2 is False:\n",
    "            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n",
    "            return accuracy1, accuracy2\n",
    "        else:\n",
    "            prediction = pred.eval({X: test_input})\n",
    "            if prediction[0][1]>prediction[0][0]:\n",
    "                print('Genuine Image')\n",
    "                return True\n",
    "            else:\n",
    "                print('Forged Image')\n",
    "                return False\n",
    "\n",
    "\n",
    "\n",
    "evaluate(train_path, test_path, type2=True) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
